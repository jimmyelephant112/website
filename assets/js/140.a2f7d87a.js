(window.webpackJsonp=window.webpackJsonp||[]).push([[140],{501:function(t,s,a){"use strict";a.r(s);var n=a(1),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"transforming-data"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transforming-data"}},[t._v("#")]),t._v(" Transforming Data")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://colab.research.google.com/drive/1C4dFWDExyxzGIwLUovrDQZghZK4JK2PD",target:"_blank",rel:"noopener noreferrer"}},[a("img",{attrs:{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open in Colab"}}),a("OutboundLink")],1)]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("Both the transform functionality and this document are in the draft state. It’s under active development and will be stabilized by the end of 2020.")])])]),t._v(" "),a("p",[t._v("Transforming data in Frictionless means modifying a data + metadata from the state A to the state B. For example, it can be a dirty Excel file we need to transform to a cleaned CSV file or a folder of data files we want to update and save as a data package.")]),t._v(" "),a("p",[t._v("For the core transform functions Frictionless uses amazing "),a("a",{attrs:{href:"https://petl.readthedocs.io/en/stable/",target:"_blank",rel:"noopener noreferrer"}},[t._v("PETL"),a("OutboundLink")],1),t._v(" project under the hood. This library provides lazy-loading functinality in running data pipelines. On top of it Frictionless adds metadata management and a bridge between already familiar concepts like Pacakge/Resource and PETL’s processors.")]),t._v(" "),a("p",[t._v("Frictionless supports a few different kinds of data and metadata transformations:")]),t._v(" "),a("ul",[a("li",[t._v("resource and package transforms")]),t._v(" "),a("li",[t._v("transforms based on a declarative pipeline")])]),t._v(" "),a("p",[t._v("The main difference between the first two and pipelines that resource and package transforms are imperative while pipelines can be created beforehand or shared as a JSON file. Also, Frictionless supports a "),a("a",{attrs:{href:"https://colab.research.google.com/drive/1MbEhvyrIIW6lExySC48pakjLSAqxHj3t",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dataflows"),a("OutboundLink")],1),t._v(" pipeline runner. You need to install the "),a("code",[t._v("dataflows")]),t._v(" plugin to use it.")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v(" pip "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" frictionless\n")])])]),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("wget")]),t._v(" -q -O transform.csv https://raw.githubusercontent.com/frictionlessdata/frictionless-py/master/data/transform.csv\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cat")]),t._v(" transform.csv\n")])])]),a("pre",[a("code",[t._v("id,name,population\n1,germany,83\n2,france,66\n3,spain,47\n")])]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("wget")]),t._v(" -q -O transform-groups.csv https://raw.githubusercontent.com/frictionlessdata/frictionless-py/master/data/transform-groups.csv\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cat")]),t._v(" transform-groups.csv\n")])])]),a("pre",[a("code",[t._v("id,name,population,year\n1,germany,83,2020\n2,germany,77,1920\n3,france,66,2020\n4,france,54,1920\n5,spain,47,2020\n6,spain,33,1920\n")])]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("wget")]),t._v(" -q -O transform-pivot.csv https://raw.githubusercontent.com/frictionlessdata/frictionless-py/master/data/transform-pivot.csv\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cat")]),t._v(" transform-pivot.csv\n")])])]),a("pre",[a("code",[t._v("region,gender,style,units\neast,boy,tee,12\neast,boy,golf,14\neast,boy,fancy,7\neast,girl,tee,3\neast,girl,golf,8\neast,girl,fancy,18\nwest,boy,tee,12\nwest,boy,golf,15\nwest,boy,fancy,8\nwest,girl,tee,6\nwest,girl,golf,16\nwest,girl,fancy,1\n")])]),t._v(" "),a("h2",{attrs:{id:"transform-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transform-functions"}},[t._v("#")]),t._v(" Transform Functions")]),t._v(" "),a("p",[t._v("The high-level interface for transforming data provided by Frictionless is a set of "),a("code",[t._v("transform")]),t._v(" functions:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("transform")]),t._v(": it will detect the source type and transform data accordingly")]),t._v(" "),a("li",[a("code",[t._v("transform_resource")]),t._v(": it transforms a resource")]),t._v(" "),a("li",[a("code",[t._v("transform_package")]),t._v(": it transforms a package")]),t._v(" "),a("li",[a("code",[t._v("transform_pipeline")]),t._v(": it transforms resource or package based on a declarative pipeline definition")])]),t._v(" "),a("h3",{attrs:{id:"transforming-resource"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transforming-resource"}},[t._v("#")]),t._v(" Transforming Resource")]),t._v(" "),a("p",[t._v("Let’s write our first transform. It’s as easy as defining a source resource, applying transform steps and getting back a resulting target resource:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_melt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'},\n            {'name': 'variable'},\n            {'name': 'value'}]}\n[Row([('name', 'germany'), ('variable', 'id'), ('value', 1)]),\n Row([('name', 'germany'), ('variable', 'population'), ('value', 83)]),\n Row([('name', 'france'), ('variable', 'id'), ('value', 2)]),\n Row([('name', 'france'), ('variable', 'population'), ('value', 66)]),\n Row([('name', 'spain'), ('variable', 'id'), ('value', 3)]),\n Row([('name', 'spain'), ('variable', 'population'), ('value', 47)])]\n")])]),t._v(" "),a("p",[t._v("Let’s break the transorming steps we applied down:")]),t._v(" "),a("ol",[a("li",[a("code",[t._v("steps.table_normalize")]),t._v(" - cast data types and shape the table according to the schema, inferred or provided")]),t._v(" "),a("li",[a("code",[t._v("steps.table_melt")]),t._v(" - melt the table as it’s done in R-Language or in other scientific libraries like "),a("code",[t._v("pandas")])])]),t._v(" "),a("p",[t._v("Thare are dozens of other available steps that will be covered below.")]),t._v(" "),a("h3",{attrs:{id:"transforming-package"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transforming-package"}},[t._v("#")]),t._v(" Transforming Package")]),t._v(" "),a("p",[t._v("Transforming a package is not much more difficult than a resource. Basically, a package is a set of resources so we will be transforming resources exactly the same way as we did above + we will be managing the resources list itself, adding or removing them:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resources"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'transform.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n            steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_merge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_sort"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_names"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"extra"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("['main']\n{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[t._v("The exact tranformation we have applied actually doesn’t make any sense as we just duplicted every row of the "),a("code",[t._v("main")]),t._v(" resource. But it must have provided basic undetstanding of how simple and at the same time flexible package transformations can be.")]),t._v(" "),a("h3",{attrs:{id:"transforming-pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transforming-pipeline"}},[t._v("#")]),t._v(" Transforming Pipeline")]),t._v(" "),a("p",[t._v("A pipeline is a metadata object having one of these types:")]),t._v(" "),a("ul",[a("li",[t._v("resource")]),t._v(" "),a("li",[t._v("package")]),t._v(" "),a("li",[t._v("dataflows")]),t._v(" "),a("li",[t._v("others (depending on custom plugins you use)")])]),t._v(" "),a("p",[t._v("For resource and package types it’s basically the same functionality as we have seen above but written declaratively. So let’s just run the same resource transformation as we did in the "),a("code",[t._v("Tranforming Resource")]),t._v(" section:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Pipeline"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\npipeline "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Pipeline"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'type'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'resource'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'source'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'path'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'transform.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'steps'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'type'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tableNormalize'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'spec'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'type'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tableMelt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'spec'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldName'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pipeline"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'},\n            {'name': 'variable'},\n            {'name': 'value'}]}\n[Row([('name', 'germany'), ('variable', 'id'), ('value', 1)]),\n Row([('name', 'germany'), ('variable', 'population'), ('value', 83)]),\n Row([('name', 'france'), ('variable', 'id'), ('value', 2)]),\n Row([('name', 'france'), ('variable', 'population'), ('value', 66)]),\n Row([('name', 'spain'), ('variable', 'id'), ('value', 3)]),\n Row([('name', 'spain'), ('variable', 'population'), ('value', 47)])]\n")])]),t._v(" "),a("p",[t._v("And as we had expected we got the same result.")]),t._v(" "),a("h2",{attrs:{id:"transform-options"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transform-options"}},[t._v("#")]),t._v(" Transform Options")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("transorm")]),t._v(" function accepts the "),a("code",[t._v("source")]),t._v(" argument which can be a resource, a package or a pipeline descriptor")]),t._v(" "),a("p",[a("strong",[t._v("Resource")])]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("transform_resource")]),t._v(" function also accepts:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("steps")]),t._v(" argument to define which steps should be applied on the source resource.")])]),t._v(" "),a("p",[a("strong",[t._v("Package")])]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("transform_package")]),t._v(" function also accepts:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("steps")]),t._v(" argument to define which steps should be applied on the source package.")])]),t._v(" "),a("p",[a("strong",[t._v("Pipeline")])]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("transform_pipeline")]),t._v(" function doesn’t accept any additional arguments.")]),t._v(" "),a("h2",{attrs:{id:"transform-principles"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transform-principles"}},[t._v("#")]),t._v(" Transform Principles")]),t._v(" "),a("p",[t._v("Frictionless Transforms bases on a few core principles which is shared with other parts of the framework:")]),t._v(" "),a("p",[a("strong",[t._v("Conceptual Simplicity")])]),t._v(" "),a("p",[t._v("Frictionless Transforms is not more than a list of functions that accept a source resource/package object and return a target resource/package object. Every function just updates the input’s metadata and data and that’s it. Thanks to this simplicity even a non-techical user can read the "),a("a",{attrs:{href:"https://github.com/frictionlessdata/frictionless-py/blob/7ad8e692ad00131cdc9fa51258d8b860c62e77bc/frictionless/transform/resource.py#L7",target:"_blank",rel:"noopener noreferrer"}},[t._v("source code"),a("OutboundLink")],1),t._v(" of the transform function and understand how it works. And understanding the tools you use can be really important for mastering them.")]),t._v(" "),a("p",[a("strong",[t._v("Metadata Matters")])]),t._v(" "),a("p",[t._v("There is plenty of great ETL-frameworks written in Python and other languages. As said, we use one of them (PETL) under the hood. The core difference between Frictionless and others that we treat metadata as a first-class citizien. It means that you don’t loose type and other important information during the pipeline evaluation.")]),t._v(" "),a("p",[a("strong",[t._v("Data Streaming")])]),t._v(" "),a("p",[t._v("Whenever it’s possible Frictionless streams the data instead of reading it into memory. For example, for sorting big tables we use a memory usage threshold and it’s met we use file system to unload the data. Ability to stream the data give users power to work with files of any size.")]),t._v(" "),a("p",[a("strong",[t._v("Lazy Evaluation")])]),t._v(" "),a("p",[t._v("Unlike to systems like "),a("code",[t._v("Data Package Pipelines")]),t._v(" core Frictionless Transforms doesn’t have a back-pressured flow as all data manupulation happen on-demand. For example, if you transform a data package containing 10 big csv files but you only need to reshape one table Frictionless will not even read other tables. Actually, when you call "),a("code",[t._v("target = transform(source)")]),t._v(" it does almost nothing untill the data reading call like "),a("code",[t._v("target.read_rows()")]),t._v(" is made.")]),t._v(" "),a("p",[a("strong",[t._v("Lean Processing")])]),t._v(" "),a("p",[t._v("Similiar to the section above, Frictionless tries to be as much explicit as possible regarding actions taken. For example, it will not use CPU resources to cast data unless a user adds a “normalize”, “validate” or similiar steps. So it’s possible to transform rather big file without even casting types, for example, if you just need to reshape it.")]),t._v(" "),a("h2",{attrs:{id:"transform-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transform-steps"}},[t._v("#")]),t._v(" Transform Steps")]),t._v(" "),a("p",[t._v("Frictionless includes more than 40+ builtin transform steps. They are groupped by the object so you can find them easily if you have code autocomplition. Start typing, for example, "),a("code",[t._v("steps.table...")]),t._v(" and you will see all the available steps. The groups are listed below and you will find every group described in more detail in the next sections. It’s also possible to write custom transform steps. Please read the section below to learn more about it.")]),t._v(" "),a("ul",[a("li",[t._v("resource")]),t._v(" "),a("li",[t._v("table")]),t._v(" "),a("li",[t._v("field")]),t._v(" "),a("li",[t._v("row")]),t._v(" "),a("li",[t._v("cell")])]),t._v(" "),a("h2",{attrs:{id:"resource-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#resource-steps"}},[t._v("#")]),t._v(" Resource Steps")]),t._v(" "),a("p",[a("strong",[t._v("Add Resource")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resources"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'transform.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("['main', 'extra']\n{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Remove Resource")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resources"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'profile': 'data-package', 'resources': []}\n")])]),t._v(" "),a("p",[a("strong",[t._v("Transform Resource")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resources"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'transform.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n            steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_merge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'extra'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_sort"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_names"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"extra"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("['main']\n{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Update Resource")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resources"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource_update"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" title"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Main Resource'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" description"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'For the docs'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'main'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'compression': 'no',\n 'compressionPath': '',\n 'control': {'newline': ''},\n 'description': 'For the docs',\n 'dialect': {},\n 'encoding': 'utf-8',\n 'format': 'csv',\n 'hashing': 'md5',\n 'name': 'main',\n 'path': 'transform.csv',\n 'profile': 'tabular-data-resource',\n 'query': {},\n 'schema': {'fields': [{'name': 'id', 'type': 'integer'},\n                       {'name': 'name', 'type': 'string'},\n                       {'name': 'population', 'type': 'integer'}]},\n 'scheme': 'file',\n 'title': 'Main Resource'}\n")])]),t._v(" "),a("h2",{attrs:{id:"table-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#table-steps"}},[t._v("#")]),t._v(" Table Steps")]),t._v(" "),a("p",[a("strong",[t._v("Aggregate Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform-groups.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_aggregate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            group_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" aggregation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sum"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'}, {'name': 'sum'}]}\n[Row([('name', 'france'), ('sum', 120)]),\n Row([('name', 'germany'), ('sum', 160)]),\n Row([('name', 'spain'), ('sum', 80)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Attach Tables")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_attach"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"large"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mid"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'},\n            {'name': 'note', 'type': 'string'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83), ('note', 'large')]),\n Row([('id', 2), ('name', 'france'), ('population', 66), ('note', 'mid')]),\n Row([('id', 3), ('name', 'spain'), ('population', 47), ('note', None)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Debug Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_debug"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("function"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("['1', 'germany', '83']\n['2', 'france', '66']\n['3', 'spain', '47']\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Diff Tables")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_diff"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            resource"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n                data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"germany"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("83")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"france"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spain"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("47")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 2), ('name', 'france'), ('population', 66)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Intersect Tables")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_intersect"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            resource"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n                data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"germany"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("83")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"france"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spain"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("47")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Join Tables")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            resource"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"beer"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"vine"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'},\n            {'name': 'note', 'type': 'string'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83), ('note', 'beer')]),\n Row([('id', 2), ('name', 'france'), ('population', 66), ('note', 'vine')])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Melt Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_melt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'},\n            {'name': 'variable'},\n            {'name': 'value'}]}\n[Row([('name', 'germany'), ('variable', 'id'), ('value', 1)]),\n Row([('name', 'germany'), ('variable', 'population'), ('value', 83)]),\n Row([('name', 'france'), ('variable', 'id'), ('value', 2)]),\n Row([('name', 'france'), ('variable', 'population'), ('value', 66)]),\n Row([('name', 'spain'), ('variable', 'id'), ('value', 3)]),\n Row([('name', 'spain'), ('variable', 'population'), ('value', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Merge Tables")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_merge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            resource"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"malta"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"island"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'},\n            {'name': 'note', 'type': 'string'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83), ('note', None)]),\n Row([('id', 2), ('name', 'france'), ('population', 66), ('note', None)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47), ('note', None)]),\n Row([('id', 4), ('name', 'malta'), ('population', None), ('note', 'island')])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Pivot Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform-pivot.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_pivot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f1"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"region"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f2"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gender"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" f3"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"units"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" aggfun"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'region', 'type': 'string'},\n            {'name': 'boy', 'type': 'integer'},\n            {'name': 'girl', 'type': 'integer'}]}\n[Row([('region', 'east'), ('boy', 33), ('girl', 29)]),\n Row([('region', 'west'), ('boy', 35), ('girl', 23)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Print Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_print"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("==  =======  ==========\nid  name     population\n==  =======  ==========\n 1  germany          83\n 2  france           66\n 3  spain            47\n==  =======  ==========\n")])]),t._v(" "),a("p",[a("strong",[t._v("Recast Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_melt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_recast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Transpose Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_transpose"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'},\n            {'name': 'germany', 'type': 'integer'},\n            {'name': 'france', 'type': 'integer'},\n            {'name': 'spain', 'type': 'integer'}]}\n[Row([('name', 'population'), ('germany', 83), ('france', 66), ('spain', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Validate Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cell_set"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bad"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_validate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  pprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("except")]),t._v(" Exception "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" exception"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  pprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("exception"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\nFrictionlessException('[step-error] The transfrom step has an error: \"table_validate\" raises \"[type-error] The cell \"bad\" in row at position \"2\" and field \"population\" at position \"3\" has incompatible type: type is \"integer/default\"\"',)\n")])]),t._v(" "),a("p",[a("strong",[t._v("Write Table")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_write"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'transform.json'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("cat")]),t._v(" transform.json\n")])])]),a("pre",[a("code",[t._v('[\n  [\n    "id",\n    "name",\n    "population"\n  ],\n  [\n    1,\n    "germany",\n    83\n  ],\n  [\n    2,\n    "france",\n    66\n  ],\n  [\n    3,\n    "spain",\n    47\n  ]\n]\n')])]),t._v(" "),a("h2",{attrs:{id:"field-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#field-steps"}},[t._v("#")]),t._v(" Field Steps")]),t._v(" "),a("p",[a("strong",[t._v("Add Field")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"eu"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'},\n            {'name': 'note', 'type': 'string'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83), ('note', 'eu')]),\n Row([('id', 2), ('name', 'france'), ('population', 66), ('note', 'eu')]),\n Row([('id', 3), ('name', 'spain'), ('population', 47), ('note', 'eu')])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Filter Fields")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_filter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("names"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'}]}\n[Row([('id', 1), ('name', 'germany')]),\n Row([('id', 2), ('name', 'france')]),\n Row([('id', 3), ('name', 'spain')])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Move Field")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_move"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" position"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'},\n            {'name': 'id', 'type': 'integer'}]}\n[Row([('name', 'germany'), ('population', 83), ('id', 1)]),\n Row([('name', 'france'), ('population', 66), ('id', 2)]),\n Row([('name', 'spain'), ('population', 47), ('id', 3)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Remove Field")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("names"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('name', 'germany'), ('population', 83)]),\n Row([('name', 'france'), ('population', 66)]),\n Row([('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Split Field")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" to_names"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pattern"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'population', 'type': 'integer'},\n            {'name': 'name1', 'type': 'string'},\n            {'name': 'name2', 'type': 'string'}]}\n[Row([('id', 1), ('population', 83), ('name1', 'germ'), ('name2', 'ny')]),\n Row([('id', 2), ('population', 66), ('name1', 'fr'), ('name2', 'nce')]),\n Row([('id', 3), ('population', 47), ('name1', 'sp'), ('name2', 'in')])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Unpack Field")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_update"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"array"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_unpack"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" to_names"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id3"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'},\n            {'name': 'id2'},\n            {'name': 'id3'}]}\n[Row([('name', 'germany'), ('population', 83), ('id2', 1), ('id3', 1)]),\n Row([('name', 'france'), ('population', 66), ('id2', 1), ('id3', 1)]),\n Row([('name', 'spain'), ('population', 47), ('id2', 1), ('id3', 1)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Update Field")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_update"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'string'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', '1'), ('name', 'germany'), ('population', 83)]),\n Row([('id', '2'), ('name', 'france'), ('population', 66)]),\n Row([('id', '3'), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("h2",{attrs:{id:"row-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#row-steps"}},[t._v("#")]),t._v(" Row Steps")]),t._v(" "),a("p",[a("strong",[t._v("Filter Rows")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table_normalize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_filter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("predicat"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"<formula>id > 1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Search Rows")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_search"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("regex"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('r"^f.*"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 2), ('name', 'france'), ('population', 66)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Slice Rows")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_slice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("head"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'france'), ('population', 66)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Sort Rows")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_sort"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_names"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 2), ('name', 'france'), ('population', 66)]),\n Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Split Rows")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pattern"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germ'), ('population', 83)]),\n Row([('id', 1), ('name', 'ny'), ('population', 83)]),\n Row([('id', 2), ('name', 'fr'), ('population', 66)]),\n Row([('id', 2), ('name', 'nce'), ('population', 66)]),\n Row([('id', 3), ('name', 'sp'), ('population', 47)]),\n Row([('id', 3), ('name', 'in'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Subset Rows")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_update"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_subset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("subset"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"conflicts"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 1), ('name', 'france'), ('population', 66)]),\n Row([('id', 1), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Ungroup Rows")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform-groups.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("row_ungroup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("group_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" selection"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"first"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'},\n            {'name': 'year', 'type': 'integer'}]}\n[Row([('id', 3), ('name', 'france'), ('population', 66), ('year', 2020)]),\n Row([('id', 1), ('name', 'germany'), ('population', 83), ('year', 2020)]),\n Row([('id', 5), ('name', 'spain'), ('population', 47), ('year', 2020)])]\n")])]),t._v(" "),a("h2",{attrs:{id:"cell-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cell-steps"}},[t._v("#")]),t._v(" Cell Steps")]),t._v(" "),a("p",[a("strong",[t._v("Convert Cells")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cell_convert"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n/a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'n/a'), ('population', 83)]),\n Row([('id', 2), ('name', 'n/a'), ('population', 66)]),\n Row([('id', 3), ('name', 'n/a'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Fill Cells")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cell_replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"france"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" replace"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cell_fill"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"FRANCE"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'FRANCE'), ('population', 66)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Format Cells")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cell_format"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("template"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Prefix: {0}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'Prefix: germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'Prefix: france'), ('population', 66)]),\n Row([('id', 3), ('name', 'Prefix: spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Interpolate Cells")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cell_interpolate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("template"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Prefix: %s"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'Prefix: germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'Prefix: france'), ('population', 66)]),\n Row([('id', 3), ('name', 'Prefix: spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Replace Cells")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cell_replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pattern"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"france"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" replace"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"FRANCE"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 83)]),\n Row([('id', 2), ('name', 'FRANCE'), ('population', 66)]),\n Row([('id', 3), ('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("p",[a("strong",[t._v("Set Cells")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n          steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cell_set"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("field_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('id', 1), ('name', 'germany'), ('population', 100)]),\n Row([('id', 2), ('name', 'france'), ('population', 100)]),\n Row([('id', 3), ('name', 'spain'), ('population', 100)])]\n")])]),t._v(" "),a("h2",{attrs:{id:"custom-steps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#custom-steps"}},[t._v("#")]),t._v(" Custom Steps")]),t._v(" "),a("p",[t._v("Here is an example of a custom step written as a python function:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Package"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("step")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Data")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("data")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" row "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_row_stream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("del")]),t._v(" row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" row\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Meta")]),t._v("\n    target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data\n    target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("remove_field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\nsource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transform.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("{'fields': [{'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n[Row([('name', 'germany'), ('population', 83)]),\n Row([('name', 'france'), ('population', 66)]),\n Row([('name', 'spain'), ('population', 47)])]\n")])]),t._v(" "),a("h2",{attrs:{id:"transform-utils"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transform-utils"}},[t._v("#")]),t._v(" Transform Utils")]),t._v(" "),a("blockquote",[a("p",[t._v("Transform Utils is under construction")])]),t._v(" "),a("h2",{attrs:{id:"working-with-petl"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#working-with-petl"}},[t._v("#")]),t._v(" Working with PETL")]),t._v(" "),a("p",[t._v("In some cases, it’s better to use a lower-level API to achieve some goal. A resource can be exported as a PETL table. For more information please visit PETL’s "),a("a",{attrs:{href:"https://petl.readthedocs.io/en/stable/",target:"_blank",rel:"noopener noreferrer"}},[t._v("documentation portal"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource\n\nresource "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'transform.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npetl_table "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" resource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_petl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Use it with PETL framework")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("petl_table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("pre",[a("code",[t._v("+---+---------+----+\n|   |         |    |\n+===+=========+====+\n| 1 | germany | 83 |\n+---+---------+----+\n| 2 | france  | 66 |\n+---+---------+----+\n| 3 | spain   | 47 |\n+---+---------+----+\n")])]),t._v(" "),a("h2",{attrs:{id:"working-with-dataflows"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#working-with-dataflows"}},[t._v("#")]),t._v(" Working with DataFlows")]),t._v(" "),a("p",[t._v("DataFlows is a powerful framework you can also use for transforms. Please read more about it:")]),t._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/datahq/dataflows/blob/master/TUTORIAL.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("DataFlows Tutorial"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/datahq/dataflows/blob/master/PROCESSORS.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("DataFlows Processors"),a("OutboundLink")],1)])])])}),[],!1,null,null,null);s.default=e.exports}}]);