(window.webpackJsonp=window.webpackJsonp||[]).push([[119],{480:function(t,a,s){"use strict";s.r(a);var e=s(1),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"frictionless-framework"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#frictionless-framework"}},[t._v("#")]),t._v(" Frictionless Framework")]),t._v(" "),s("p",[s("code",[t._v("frictionless.js")]),t._v(" is a lightweight, standardized “stream-plus-metadata” interface for accessing files and datasets, especially tabular ones (CSV, Excel).")]),t._v(" "),s("p",[s("code",[t._v("frictionless.js")]),t._v(" follows the "),s("a",{attrs:{href:"http://okfnlabs.org/blog/2018/02/15/design-pattern-for-a-core-data-library.html#dataset",target:"_blank",rel:"noopener noreferrer"}},[t._v("“Frictionless Data Lib Pattern”"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("Open it fast")]),t._v(": simple "),s("code",[t._v("open")]),t._v(" method for data on disk, online and inline")]),t._v(" "),s("li",[s("strong",[t._v("Data plus")]),t._v(": data plus metadata (size, path, etc) in standardized way")]),t._v(" "),s("li",[s("strong",[t._v("Stream it")]),t._v(": raw streams and object streams")]),t._v(" "),s("li",[s("strong",[t._v("Tabular")]),t._v(": open CSV, Excel or arrays and get a row stream")]),t._v(" "),s("li",[s("strong",[t._v("Frictionless")]),t._v(": compatible with "),s("a",{attrs:{href:"https://frictionlessdata.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Frictionless Data standards"),s("OutboundLink")],1)])]),t._v(" "),s("p",[s("a",{attrs:{href:"https://travis-ci.org/frictionlessdata/frictionless-js",target:"_blank",rel:"noopener noreferrer"}},[s("img",{attrs:{src:"https://travis-ci.org/frictionlessdata/frictionless-js.svg?branch=master",alt:"Build Status"}}),s("OutboundLink")],1),t._v(" "),s("a",{attrs:{href:"https://gitter.im/datahubio/chat",target:"_blank",rel:"noopener noreferrer"}},[s("img",{attrs:{src:"https://img.shields.io/gitter/room/frictionlessdata/chat.svg",alt:"Gitter"}}),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("A line of code is worth a thousand words …")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("const {open} = require('frictionless.js')\n\nvar file = open('path/to/ons-mye-population-totals.xls')\n\nfile.descriptor\n  {\n    path: '/path/to/ons-mye-population-totals.xls',\n    pathType: 'local',\n    name: 'ons-mye-population-totals',\n    format: 'xls',\n    mediatype: 'application/vnd.ms-excel',\n    encoding: 'windows-1252'\n  }\n\nfile.size\n  67584\n\nfile.rows() => stream object for rows\n  // keyed by header row by default ...\n  { 'col1': 1, 'col2': 2, ... }\n  { 'col1': 10, 'col2': 20, ... }\n")])])]),t._v(" "),s("p",[s("strong",[t._v("Table of Contents")])]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#motivation"}},[t._v("Motivation")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#features"}},[t._v("Features")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#installation"}},[t._v("Installation")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#browser"}},[t._v("Browser")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#usage"}},[t._v("Usage")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#api"}},[t._v("API")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#open"}},[t._v("open")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#files"}},[t._v("Files")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#load"}},[t._v("load")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#metadata"}},[t._v("Metadata")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#stream"}},[t._v("stream")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#buffer"}},[t._v("buffer")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#rows"}},[t._v("rows")])])])]),t._v(" "),s("li",[s("a",{attrs:{href:"#datasets"}},[t._v("Datasets")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#load-1"}},[t._v("load")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#addresource"}},[t._v("addResource")])])])]),t._v(" "),s("li",[s("a",{attrs:{href:"#utilities"}},[t._v("Utilities")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#isdataset"}},[t._v("isDataset")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#parsedatasetidentifier"}},[t._v("parseDatasetIdentifier")])])])])])]),t._v(" "),s("li",[s("a",{attrs:{href:"#developers"}},[t._v("Developers")])])]),t._v(" "),s("h2",{attrs:{id:"motivation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#motivation"}},[t._v("#")]),t._v(" Motivation")]),t._v(" "),s("p",[s("code",[t._v("frictionless.js")]),t._v(" is motivated by the following use cases:")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("Data “plus”")]),t._v(": when you work with data you always find yourself needing the data itself plus a little bit more – things like where the data came from on disk (or is going to), or how large it is. This library gives you that information in a standardized way.")]),t._v(" "),s("li",[s("strong",[t._v("Convenient open")]),t._v(": the same simple "),s("code",[t._v("open")]),t._v(" method whether you are accessing data on disk, from a URL or inline data from a string, buffer or array.")]),t._v(" "),s("li",[s("strong",[t._v("Streams (or strings)")]),t._v(": standardized iterator / object stream interface to data wherever you’ve loaded from online, on disk or inline")]),t._v(" "),s("li",[s("strong",[t._v("Building block for data pipelines")]),t._v(": provides a standardized building block for more complex data processing. For example, suppose you want to load a csv file then write to JSON. That’s simple enough. But then suppose you want to delete the first 3 rows, delete the 2nd column. Now you have a more complex processing pipeline. This library provides a simple set of “data plus metadata” objects that you can pass along your pipeline.")])]),t._v(" "),s("h2",{attrs:{id:"features"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#features"}},[t._v("#")]),t._v(" Features")]),t._v(" "),s("ul",[s("li",[t._v("Easy: a single common API for local, online and inline data")]),t._v(" "),s("li",[t._v("Micro: The whole project is ~400 lines of code")]),t._v(" "),s("li",[t._v("Simple: Oriented for single purpose")]),t._v(" "),s("li",[t._v("Explicit: No hidden behaviours, no extra magic")]),t._v(" "),s("li",[t._v("Frictionlesss: uses and supports (but does not require) "),s("a",{attrs:{href:"https://frictionlessdata.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Frictionless Data"),s("OutboundLink")],1),t._v(" specs such as "),s("a",{attrs:{href:"https://frictionlessdata.io/data-packages/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Data Package"),s("OutboundLink")],1),t._v(" so you can leverage Frictionless tooling")]),t._v(" "),s("li",[t._v("Minimal glue: Use on its own or as a building block for more complex data tooling (thanks to its common minimal metadata)")])]),t._v(" "),s("h2",{attrs:{id:"installation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#installation"}},[t._v("#")]),t._v(" Installation")]),t._v(" "),s("p",[s("code",[t._v("npm install frictionless.js")])]),t._v(" "),s("h2",{attrs:{id:"browser"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#browser"}},[t._v("#")]),t._v(" Browser")]),t._v(" "),s("p",[t._v("If you want to use the it in the browser, first you need to build the bundle.")]),t._v(" "),s("p",[t._v("Run the following command to generate the bundle for the necessary JS targets")]),t._v(" "),s("p",[s("code",[t._v("yarn build")])]),t._v(" "),s("p",[t._v("This will create two bundles in the "),s("code",[t._v("dist")]),t._v(" folder. "),s("code",[t._v("node")]),t._v(" sub-folder contains build for node environment, while "),s("code",[t._v("browser")]),t._v(" sub-folder contains build for the browser. In a simple html file you can use it like this:")]),t._v(" "),s("div",{staticClass:"language-html extra-class"},[s("pre",{pre:!0,attrs:{class:"language-html"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("head")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("script")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("src")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("./dist/browser/bundle.js"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token script"}}),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("script")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("script")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token script"}},[s("span",{pre:!0,attrs:{class:"token language-javascript"}},[t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Global data lib is available here...")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'path/to/file'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("\n  ")])]),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("script")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("head")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("body")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("body")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),s("h2",{attrs:{id:"usage"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#usage"}},[t._v("#")]),t._v(" Usage")]),t._v(" "),s("p",[t._v("With a simple file:")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'frictionless.js'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// path can be local or remote")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// descriptor with metadata e.g. name, path, format, (guessed) mimetype etc")]),t._v("\nconsole"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("descriptor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// returns promise with raw stream")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" stream "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// let's get an object stream of the rows")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// (assuming it is tabular i.e. csv, xls etc)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" rows "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rows")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// entire file as a buffer")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" buffer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buffer\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//for large files you can return in chunks")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("bufferInChunks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" progress")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  console"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("progress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n")])])]),s("p",[t._v("With a Dataset:")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" Dataset "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'frictionless.js'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/path/to/directory/'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// must have datapackage.json in the directory atm")]),t._v("\n\nDataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("load")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("then")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("dataset")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// get a data file in this dataset")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resources"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"api"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#api"}},[t._v("#")]),t._v(" API")]),t._v(" "),s("h3",{attrs:{id:"open"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#open"}},[t._v("#")]),t._v(" open")]),t._v(" "),s("p",[t._v("Load a file from a path or descriptor.")]),t._v(" "),s("p",[s("code",[t._v("load(pathOrDescriptor, {basePath, format}={})")])]),t._v(" "),s("p",[t._v("There are 3 types of file source we support:")]),t._v(" "),s("ul",[s("li",[t._v("Local path")]),t._v(" "),s("li",[t._v("Remote url")]),t._v(" "),s("li",[t._v("Inline data")])]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'frictionless.js'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/path/to/file.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://example.com/data.xls'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// loading raw data")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'mydata'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  data"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// can be any javascript - an object, an array or a string or ...")]),t._v("\n    a"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    b"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Loading with a descriptor - this allows more fine-grained configuration")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The descriptor should follow the Frictionless Data Resource model")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// http://specs.frictionlessdata.io/data-resource/")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// file or url path")]),t._v("\n  path"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://example.com/data.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// a Table Schema - https://specs.frictionlessdata.io/table-schema/")]),t._v("\n  schema"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    fields"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// CSV dialect - https://specs.frictionlessdata.io/csv-dialect/")]),t._v("\n  dialect"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// this is tab separated CSV/DSV")]),t._v("\n    delimiter"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\t'")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("code",[t._v("basePath")]),t._v(": use in cases where you want to create a File with a path that is relative to a base directory / path e.g.")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("const file = data.open('data.csv', {basePath: '/my/base/path'})\n")])])]),s("p",[t._v("Will open the file: "),s("code",[t._v("/my/base/path/data.csv")])]),t._v(" "),s("p",[t._v("This functionality is primarily useful when using Files as part of Datasets where it can be convenient for a File to have a path relative to the directory of the Dataset. (See also Data Package and Data Resource in the Frictionless Data specs).")]),t._v(" "),s("h3",{attrs:{id:"files"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#files"}},[t._v("#")]),t._v(" Files")]),t._v(" "),s("p",[t._v("A single data file - local or remote.")]),t._v(" "),s("h4",{attrs:{id:"load"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#load"}},[t._v("#")]),t._v(" load")]),t._v(" "),s("p",[s("em",[t._v("DEPRECATED")]),t._v(". Use simple "),s("code",[t._v("open")]),t._v(".")]),t._v(" "),s("h4",{attrs:{id:"metadata"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#metadata"}},[t._v("#")]),t._v(" Metadata")]),t._v(" "),s("p",[t._v("Main metadata is available via the "),s("code",[t._v("descriptor")]),t._v(":")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("file.descriptor\n")])])]),s("p",[t._v("This metadata is a combination of the metadata passed in at File creation (if you created the File with a descriptor object) and auto-inferred information from the File path. This is the info that is auto-inferred:")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("path: path this was instantiated with - may not be same as file.path (depending on basePath)\npathType: remote | local\nname:   file name (without extension)\nformat: the extension\nmediatype: mimetype based on file name and extension\n")])])]),s("p",[t._v("In addition to this metadata there are certain properties which are computed on demand:")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the full path to the file (using basepath)")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// md5 hash of the file")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// sha256 hash of the file")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" hash256 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hashType"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sha256'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// file encoding")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" encoding "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encoding\n")])])]),s("p",[s("strong",[t._v("Note")]),t._v(": size, hash are not available for remote Files (those created from urls).")]),t._v(" "),s("h4",{attrs:{id:"stream"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#stream"}},[t._v("#")]),t._v(" stream")]),t._v(" "),s("p",[s("code",[t._v("stream()")])]),t._v(" "),s("p",[t._v("Get readable stream")]),t._v(" "),s("p",[t._v("@returns Promise with readable stream object on resolve")]),t._v(" "),s("h4",{attrs:{id:"buffer"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#buffer"}},[t._v("#")]),t._v(" buffer")]),t._v(" "),s("p",[s("code",[t._v("File.buffer")])]),t._v(" "),s("p",[t._v("Get this file as a buffer (async)")]),t._v(" "),s("p",[t._v("@returns: promise which resolves to the buffer")]),t._v(" "),s("h4",{attrs:{id:"rows"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rows"}},[t._v("#")]),t._v(" rows")]),t._v(" "),s("p",[s("code",[t._v("rows({keyed}={})")])]),t._v(" "),s("p",[t._v("Get the rows for this file as a node object stream (assumes underlying data is tabular!)")]),t._v(" "),s("p",[t._v("@returns Promise with rows as parsed JS objects (depends on file format)")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("keyed")]),t._v(": if "),s("code",[t._v("false")]),t._v(" (default) returns rows as arrays. If "),s("code",[t._v("true")]),t._v(" returns rows as objects.")])]),t._v(" "),s("p",[t._v("TODO: casting (does data get cast automatically for you or not …)")]),t._v(" "),s("p",[s("strong",[t._v("What formats are supported?")])]),t._v(" "),s("p",[t._v("The rows functionality is currently available for CSV and Excel files. The Tabular support incorporates supports for Table Schema and CSV Dialect e.g. you can do:")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// load a CSV with a non-standard dialect e.g. tab separated or semi-colon separated")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  path"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'mydata.tsv'")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Full support for http://specs.frictionlessdata.io/csv-dialect/")]),t._v("\n  dialect"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    delimiter"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\t'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// for tabs or ';' for semi-colons etc")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// open a CSV with a Table Schema")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  path"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'mydata.csv'")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Full support for Table Schema https://specs.frictionlessdata.io/table-schema/")]),t._v("\n  schema"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    fields"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Column 1'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        type"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'integer'")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"datasets"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#datasets"}},[t._v("#")]),t._v(" Datasets")]),t._v(" "),s("p",[t._v("A collection of data files with optional metadata.")]),t._v(" "),s("p",[t._v("Under the hood it heavily uses Data Package formats and it natively supports Data Package formats including loading from "),s("code",[t._v("datapackage.json")]),t._v(" files. However, it does not require knowledge or use of Data Packages.")]),t._v(" "),s("p",[t._v("A Dataset has four primary properties:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("descriptor")]),t._v(": key metadata. The descriptor follows the Data Package spec")]),t._v(" "),s("li",[s("code",[t._v("resources")]),t._v(": an array of the Files contained in this Dataset")]),t._v(" "),s("li",[s("code",[t._v("identifier")]),t._v(": the identifier encapsulates the location (or origin) of this Dataset")]),t._v(" "),s("li",[s("code",[t._v("readme")]),t._v(": the README for this Dataset (if it exists). The readme content is taken from the "),s("a",{attrs:{href:"http://README.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("README.md"),s("OutboundLink")],1),t._v(" file located in the Dataset root directory, or, if that does not exist from the "),s("code",[t._v("readme")]),t._v(" property on the descriptor. If neither of those exist the readme will be undefined or null.")])]),t._v(" "),s("p",[t._v("In addition we provide the convenience attributes:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("path")]),t._v(": the path (remote or local) to this dataset")]),t._v(" "),s("li",[s("code",[t._v("dataPackageJsonPath")]),t._v(": the path to the "),s("code",[t._v("datapackage.json")]),t._v(" for this Dataset (if it exists)")])]),t._v(" "),s("h4",{attrs:{id:"load-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#load-2"}},[t._v("#")]),t._v(" load")]),t._v(" "),s("p",[t._v("To create a new Dataset object use "),s("code",[t._v("Dataset.load")]),t._v(". It takes descriptor Object or identifier string:")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("async Dataset.load(pathOrDescriptor, {owner = null} = {})\n")])])]),s("ul",[s("li",[s("code",[t._v("pathOrDescriptor")]),t._v(" - can be one of:\n"),s("ul",[s("li",[t._v("local path to Dataset")]),t._v(" "),s("li",[t._v("remote url to Dataset")]),t._v(" "),s("li",[t._v("descriptor object")])])]),t._v(" "),s("li",[t._v("@returns: a fully loaded Dataset (parsed and used "),s("code",[t._v("datapackage.json")]),t._v(" and "),s("code",[t._v("README.md")]),t._v(" – if README exists)")])]),t._v(" "),s("p",[t._v("For example:")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'frictionless.js'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" pathOrDescriptor "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://raw.githubusercontent.com/datasets/co2-ppm/master/datapackage.json'")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" dataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("load")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pathOrDescriptor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"addresource"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#addresource"}},[t._v("#")]),t._v(" addResource")]),t._v(" "),s("p",[t._v("Add a resource to the Dataset:")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("addResource")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ul",[s("li",[s("code",[t._v("resource")]),t._v(": may be an already instantiated File object or it is a resource descriptor")]),t._v(" "),s("li",[t._v("@returns: null")])]),t._v(" "),s("h3",{attrs:{id:"utilities"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#utilities"}},[t._v("#")]),t._v(" Utilities")]),t._v(" "),s("h4",{attrs:{id:"isdataset"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#isdataset"}},[t._v("#")]),t._v(" isDataset")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// seeks to guess whether a given path is the path to a Dataset or a File")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// (i.e. a directory or datapackage.json)")]),t._v("\ndata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("isDataset")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"parsedatasetidentifier"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#parsedatasetidentifier"}},[t._v("#")]),t._v(" parseDatasetIdentifier")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// parses dataset path and returns identifier dictionary")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// handles local paths, remote URLs as well as DataHub and GitHub specific URLs")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// (e.g., https://datahub.io/core/finance-vix or https://github.com/datasets/finance-vix")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" identifier "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("parseDatasetIdentifier")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nconsole"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("identifier"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("and it prints out:")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("{\n    name: <name>,\n    owner: <owner>,\n    path: <path>,\n    type: <type>,\n    original: <path>,\n    version: <version>\n}\n")])])]),s("h2",{attrs:{id:"developers"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#developers"}},[t._v("#")]),t._v(" Developers")]),t._v(" "),s("p",[t._v("Requirements:")]),t._v(" "),s("ul",[s("li",[t._v("NodeJS >= v8.10.0")]),t._v(" "),s("li",[t._v("NPM >= v5.2.0")])]),t._v(" "),s("h3",{attrs:{id:"test"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#test"}},[t._v("#")]),t._v(" Test")]),t._v(" "),s("p",[t._v("We have two type of tests Karma based for browser testing and Mocha with Chai for Node. All node tests are in "),s("code",[t._v("datajs/test")]),t._v(" folder. Since Mocha is sensitive to test namings, we have separate the folder "),s("code",[t._v("/browser-test")]),t._v(" for only Karma.")]),t._v(" "),s("ul",[s("li",[t._v("To run browser test, first you need to build the library in order to have the bundle in "),s("code",[t._v("dist/browser")]),t._v(" folder. Run: "),s("code",[t._v("yarn build:browser")]),t._v(" to achieve this, then for browser testing use the command "),s("code",[t._v("yarn test:browser")]),t._v(", this will run Karma tests.")]),t._v(" "),s("li",[t._v("To test in Node: "),s("code",[t._v("yarn test:node")])]),t._v(" "),s("li",[t._v("To run all tests including Node and browser run "),s("code",[t._v("yarn test")])]),t._v(" "),s("li",[t._v("To watch Node test run: "),s("code",[t._v("yarn test:node:watch")])])]),t._v(" "),s("h3",{attrs:{id:"setup"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#setup"}},[t._v("#")]),t._v(" Setup")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("Git clone the repo")])]),t._v(" "),s("li",[s("p",[t._v("Install dependencies: "),s("code",[t._v("yarn")])])]),t._v(" "),s("li",[s("p",[t._v("To make the browser and node test work, first run the build: "),s("code",[t._v("yarn build")])])]),t._v(" "),s("li",[s("p",[t._v("Run tests: "),s("code",[t._v("yarn test")])])]),t._v(" "),s("li",[s("p",[t._v("Do some dev work")])]),t._v(" "),s("li",[s("p",[t._v("Once done, make sure tests are passing. Then build distribution version of the app - "),s("code",[t._v("yarn build")]),t._v(".")]),t._v(" "),s("p",[t._v("Run "),s("code",[t._v("yarn build")]),t._v(" to compile using webpack and babel for different node and web target. To watch the build run: "),s("code",[t._v("yarn build:watch")]),t._v(".")])]),t._v(" "),s("li",[s("p",[t._v("Now proceed to “Deployment” stage")])])]),t._v(" "),s("h3",{attrs:{id:"deployment"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deployment"}},[t._v("#")]),t._v(" Deployment")]),t._v(" "),s("ol",[s("li",[t._v("Update version number in "),s("code",[t._v("package.json")]),t._v(".")]),t._v(" "),s("li",[t._v("Git commit: "),s("code",[t._v('git commit -m "some message, eg, version"')]),t._v(".")]),t._v(" "),s("li",[t._v("Release: "),s("code",[t._v('git tag -a v0.12.0 -m "some message"')]),t._v(".")]),t._v(" "),s("li",[t._v("Push: "),s("code",[t._v("git push origin master --tags")])]),t._v(" "),s("li",[t._v("Publish to NPM: "),s("code",[t._v("npm publish")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);